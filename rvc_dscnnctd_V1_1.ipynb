{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GnZdaTi6FgHf"
      ],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xavikla555/MultiExact/blob/main/rvc_dscnnctd_V1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RVC v2 Disconnected\n",
        "\n",
        "**Notebook hastily written by [Kit Lemonfoot](https://huggingface.co/Kit-Lemonfoot) / [Noel Shirogane's High Flying Birds](https://www.youtube.com/@NoelShiroganesHighFlyingBirds)**\n",
        "\n",
        "*Based on the work of the [RVC Project](https://github.com/RVC-Project), [Mangio261](https://github.com/Mangio621/), [Kalomaze](https://github.com/kalomaze), [Alexlnkp](https://github.com/alexlnkp), the [Pony Preservation Project](https://boards.4channel.org/mlp/catalog#s=Pony%20Preservation%20Project), and many others in the RVC / voice AI community* ❤\n",
        "\n",
        "*Notebook version:* **0.28** / reastered V1.2\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This notebook is designed to be used with training Retreival-Based Voice Conversion models without using a WеbUl. This is done to stay within the scope of Colab's TOS (and also because I personally don't like WеbUls.)\n",
        "\n",
        "This notebook is *not* designed to be used for inference. Colab should not be used for RVC inference in general, use local inference instead. (RVC can inference just fine on any dime-a-dozen CPU from the past 7 years, you seriously don't need Colab.)\n",
        "\n",
        "⚠ WARNING: Unlike the original RVC notebook, *this notebook ***does not*** have autosave functionality* due to the massive amount of underlying stress that RVC's autosave features places on Colab to Drive communication. Please be careful and try to keep training sessions short."
      ],
      "metadata": {
        "id": "FrR4hoSR50Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You will likely want a disconnect prevention method to keep Colab from timing you out for \"inactivity\" during training.\n",
        "# I won't be providing one here, but they're not hard to come by. Search around the Colab AI community and you'll find one. ;)"
      ],
      "metadata": {
        "id": "Q7JhsK5oYByc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies\n",
        "Run me first!"
      ],
      "metadata": {
        "id": "GnZdaTi6FgHf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBpJW3YB5zu1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install Dependencies\n",
        "import subprocess\n",
        "\n",
        "packages = ['build-essential', 'python3-dev', 'ffmpeg', 'aria2']\n",
        "pip_packages = ['pip', 'setuptools', 'wheel', 'faiss-gpu', 'fairseq', 'ffmpeg', 'ffmpeg-python', 'praat-parselmouth', 'pyworld', 'numpy==1.23.5', 'numba==0.56.4', 'librosa==0.9.2']\n",
        "print(\"Updating and installing system packages...\")\n",
        "for package in packages:\n",
        "  print(f\"Installing {package}...\")\n",
        "  subprocess.check_call(['apt-get', 'install', '-qq', '-y', package])\n",
        "\n",
        "print(\"Updating and installing pip packages...\")\n",
        "subprocess.check_call(['pip', 'install', '--upgrade'] + pip_packages)\n",
        "\n",
        "print('Packages up to date.')\n",
        "firsttry = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Repositories\n",
        "import os\n",
        "\n",
        "# READ ME BEFORE CHANGING THINGS\n",
        "# If you're attempting to replace the imports here with Applio-RVC, it will not work due to requirement discrepancies across the entire notebook.\n",
        "# I will not be porting this notebook to Applio due to the failure of the Applio team to provide backwards compatibility with the Crepe and Mangio-Crepe f0 feature format.\n",
        "# DO NOT ASK. IT WILL NOT HAPPEN.\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "if(os.path.exists(\"/content/Mangio-RVC-Fork\")):\n",
        "  print(\"RVC already installed, skipping.\")\n",
        "else:\n",
        "  #Credit to miaaaa0a on the AI Hub Discord for (indirectly) suggesting this variant of Mangio RVC to me.\n",
        "  !git clone -b pr-optimization --single-branch https://github.com/alexlnkp/Mangio-RVC-Tweaks.git\n",
        "  #Rename to keep backwards compatibility with old variants of Disconnected\n",
        "  os.rename(\"/content/Mangio-RVC-Tweaks\", \"/content/Mangio-RVC-Fork\")\n",
        "  !git clone https://github.com/maxrmorrison/torchcrepe.git\n",
        "  !mv torchcrepe/torchcrepe Mangio-RVC-Fork/\n",
        "  !rm -rf torchcrepe  # Delete the torchcrepe repository folder\n",
        "\n",
        "os.chdir('/content/Mangio-RVC-Fork')\n",
        "now_dir = \"/content/Mangio-RVC-Fork\"\n",
        "os.makedirs(os.path.join(now_dir, \"logs\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(now_dir, \"weights\"), exist_ok=True)"
      ],
      "metadata": {
        "id": "McbFvkWfJQCO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GPU Check\n",
        "import torch\n",
        "\n",
        "ngpu = torch.cuda.device_count()\n",
        "gpu_infos = []\n",
        "mem = []\n",
        "if_gpu_ok = False\n",
        "\n",
        "if torch.cuda.is_available() or ngpu != 0:\n",
        "  for i in range(ngpu):\n",
        "    gpu_name = torch.cuda.get_device_name(i)\n",
        "    if any(\n",
        "        value in gpu_name.upper()\n",
        "        for value in [\"10\", \"16\", \"20\", \"30\", \"40\", \"A2\", \"A3\", \"A4\", \"P4\", \"A50\", \"500\", \"A60\", \"70\", \"80\", \"90\", \"M4\", \"T4\", \"TITAN\"]\n",
        "    ):\n",
        "      if_gpu_ok = True\n",
        "      print(\"Compatible GPU detected: %s\" % gpu_name)\n",
        "      gpu_infos.append(\"%s\\t%s\" % (i, gpu_name))\n",
        "      mem.append(int(torch.cuda.get_device_properties(i).total_memory / 1024 / 1024 / 1024 + 0.4))\n",
        "\n",
        "if if_gpu_ok and len(gpu_infos) > 0:\n",
        "  gpu_info = \"\\n\".join(gpu_infos)\n",
        "\n",
        "else:\n",
        "  raise Exception(\"No GPU detected; training cannot continue. Please change your runtime type to a GPU.\")\n",
        "gpus = \"-\".join(i[0] for i in gpu_infos)"
      ],
      "metadata": {
        "id": "E4W8p1ZLLXLy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Drive\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print('Drive is already mounted. Proceed.')\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/rvcDisconnected', exist_ok=True)"
      ],
      "metadata": {
        "id": "1i1eYRMYfE79",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Extra Files\n",
        "#Didn't ask.\n",
        "\n",
        "#Hubert/RMVPE\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/hubert_base.pt -d /content/Mangio-RVC-Fork -o hubert_base.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Xavikla/doesntalk/resolve/main/rmvpe.pt -d /content/Mangio-RVC-Fork -o rmvpe.pt\n",
        "\n",
        "#FM JSONs\n",
        "!rm -rf /content/Mangio-RVC-Fork/configs/32k.json\n",
        "!rm -rf /content/Mangio-RVC-Fork/configs/40k.json\n",
        "!rm -rf /content/Mangio-RVC-Fork/configs/48k.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/32k.json -d /content/Mangio-RVC-Fork/configs -o 32k.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/40k.json -d /content/Mangio-RVC-Fork/configs -o 40k.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/48k.json -d /content/Mangio-RVC-Fork/configs -o 48k.json"
      ],
      "metadata": {
        "id": "v_zQGeguKD5s",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup CSVDB\n",
        "#...Alright, you made your point.\n",
        "import csv\n",
        "\n",
        "if not os.path.isdir(\"csvdb/\"):\n",
        "  os.makedirs(\"csvdb\")\n",
        "  frmnt, stp = open(\"csvdb/formanting.csv\", \"w\", newline=\"\"), open(\"csvdb/stop.csv\", \"w\", newline=\"\")\n",
        "  csv_writer = csv.writer(frmnt, delimiter=\",\")\n",
        "  csv_writer.writerow([False, 1.0, 1.0])\n",
        "  csv_writer = csv.writer(stp, delimiter=\",\")\n",
        "  csv_writer.writerow([False])\n",
        "  frmnt.close()\n",
        "  stp.close()\n",
        "\n",
        "global DoFormant, Quefrency, Timbre\n",
        "DoFormant, Quefrency, Timbre = False, 1.0, 1.0"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0LGNhYjGaBBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup\n",
        "You need to run these cells for every training session."
      ],
      "metadata": {
        "id": "oi6yLWNM31rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set Training Variables\n",
        "now_dir = \"/content/Mangio-RVC-Fork\"\n",
        "experiment_name = \"QUEBONAFIDE\" #@param {type:\"string\"}\n",
        "path_to_training_folder = \"/content/dataset/\"\n",
        "model_architecture = \"v2\" #@param [\"v1\",\"v2\"] {allow-input: false}\n",
        "target_sample_rate = \"40k\" #@param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n",
        "speaker_id = 0 #@param {type:\"integer\"}\n",
        "pitch_extraction_algorithm = \"rmvpe\" #@param [\"harvest\", \"crepe\", \"mangio-crepe\", \"rmvpe\"] {allow-input: false}\n",
        "crepe_hop_length = 2 #@param {type:\"integer\"}\n",
        "pitch_guidance = True #@param {type:\"boolean\"}\n",
        "\n",
        "cpu_threads = !nproc\n",
        "cpu_threads = int(cpu_threads[0])\n",
        "\n",
        "exp_dir = f\"{now_dir}/logs/{experiment_name}\"\n",
        "\n",
        "assert crepe_hop_length!=None, \"You need to input something for crepe_hop_length, silly.\"\n",
        "assert crepe_hop_length>0, \"Hop length must be more than 0.\"\n",
        "assert crepe_hop_length<=512, \"Save frequency must be less than 512.\"\n",
        "\n",
        "if(experiment_name == \"experiment_name\"):\n",
        "  print(\"Warning: Your experiment name should be changed to the name of your dataset.\")"
      ],
      "metadata": {
        "id": "ZodNcumpg-JM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Pretrained Model\n",
        "#@markdown What pretrained model would you like to use?\n",
        "pretrain_type = \"TITAN\" #@param [\"original\", \"OV2Super\", \"RIN_E3\", \"ItaIla\", \"SnowieV3\", \"SnowieV3xRIN_E3\", \"TITAN\", \"custom\"] {allow-input: false}\n",
        "#@markdown **Advanced:** Set your pretrain type to \"custom\" and input HuggingFace links to your G and D files here.\n",
        "g=\"\" #@param {type:\"string\"}\n",
        "d=\"\" #@param {type:\"string\"}\n",
        "assert 'model_architecture' in locals(), \"Hold up! You need to run Set Training Variables first.\"\n",
        "\n",
        "if pretrain_type!=\"original\" and model_architecture!=\"v2\":\n",
        "  model_architecture=\"v2\"\n",
        "  print(\"The new pretrains only support RVC v2 at this time. Your settings have been automatically adjusted.\")\n",
        "\n",
        "if pretrain_type==\"OV2Super\" and target_sample_rate==\"48k\":\n",
        "  target_sample_rate=\"40k\"\n",
        "  print(\"OV2Super only supports 40k and lower at this time. Your settings have been automatically adjusted.\")\n",
        "if pretrain_type==\"RIN_E3\" and target_sample_rate!=\"40k\":\n",
        "  target_sample_rate=\"40k\"\n",
        "  print(\"RIN_E3 only supports 40k at this time. Your settings have been automatically adjusted.\")\n",
        "if pretrain_type==\"ItaIla\" and target_sample_rate!=\"32k\":\n",
        "  target_sample_rate=\"32k\"\n",
        "  print(\"ItaIla only supports 32k at this time. Your settings have been automatically adjusted.\")\n",
        "if pretrain_type==\"SnowieV3xRIN_E3\" and target_sample_rate!=\"40k\":\n",
        "  target_sample_rate=\"40k\"\n",
        "  print(\"SnowieV3 x RIN_E3 only supports 40k at this time. Your settings have been automatically adjusted.\")\n",
        "if pretrain_type==\"TITAN\" and target_sample_rate==\"48k\":\n",
        "  target_sample_rate=\"40k\"\n",
        "  print(\"TITAN only supports 40k and lower at this time. Your settings have been automatically adjusted.\")\n",
        "\n",
        "\n",
        "#Setup link\n",
        "print(\"Setting up...\")\n",
        "if pretrain_type==\"original\" and model_architecture==\"v2\":\n",
        "  g = f\"https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G{target_sample_rate}.pth\"\n",
        "  d = f\"https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D{target_sample_rate}.pth\"\n",
        "if pretrain_type==\"original\" and model_architecture==\"v1\":\n",
        "  g = f\"https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0G{target_sample_rate}.pth\"\n",
        "  d = f\"https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0D{target_sample_rate}.pth\"\n",
        "if pretrain_type==\"OV2Super\" and target_sample_rate==\"40k\":\n",
        "  g = f\"https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super{target_sample_rate}G.pth\"\n",
        "  d = f\"https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super{target_sample_rate}D.pth\"\n",
        "if pretrain_type==\"OV2Super\" and target_sample_rate==\"32k\":\n",
        "  g = f\"https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/f0Ov2Super32kD.pth\"\n",
        "  d = f\"https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/f0Ov2Super32kD.pth\"\n",
        "if pretrain_type==\"RIN_E3\":\n",
        "  g = \"https://huggingface.co/MUSTAR/RIN_E3/resolve/main/RIN_E3_G.pth\"\n",
        "  d = \"https://huggingface.co/MUSTAR/RIN_E3/resolve/main/RIN_E3_D.pth\"\n",
        "if pretrain_type==\"SnowieV3\":\n",
        "  g = f\"https://huggingface.co/MUSTAR/SnowieV3.1-{target_sample_rate}/resolve/main/G_SnowieV3.1_{target_sample_rate}.pth\"\n",
        "  d = f\"https://huggingface.co/MUSTAR/SnowieV3.1-{target_sample_rate}/resolve/main/D_SnowieV3.1_{target_sample_rate}.pth\"\n",
        "if pretrain_type==\"ItaIla\":\n",
        "  g = \"https://huggingface.co/TheStinger/itaila/resolve/main/ItaIla_32k_G.pth\"\n",
        "  d = \"https://huggingface.co/TheStinger/itaila/resolve/main/ItaIla_32k_D.pth\"\n",
        "if pretrain_type==\"SnowieV3xRIN_E3\":\n",
        "  g = \"https://huggingface.co/MUSTAR/SnowieV3.1-X-RinE3-40K/resolve/main/G_Snowie-X-Rin_40k.pth\"\n",
        "  d = \"https://huggingface.co/MUSTAR/SnowieV3.1-X-RinE3-40K/resolve/main/D_Snowie-X-Rin_40k.pth\"\n",
        "if pretrain_type==\"TITAN\":\n",
        "  g = f\"https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/{target_sample_rate}/pretrained/G-f0{target_sample_rate}-TITAN-Medium.pth\"\n",
        "  d = f\"https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/{target_sample_rate}/pretrained/D-f0{target_sample_rate}-TITAN-Medium.pth\"\n",
        "\n",
        "pretrained_base = \"pretrained/\" if model_architecture == \"v1\" else \"pretrained_v2/\"\n",
        "unpt = f\"_{pretrain_type}\" if pretrain_type!=\"original\" else \"\"\n",
        "\n",
        "print(\"Downloading your pretrained model...\")\n",
        "!aria2c --console-log-level=error -q -c -x 16 -s 16 -k 1M {g} -d /content/Mangio-RVC-Fork/{pretrained_base} -o f0G{target_sample_rate}{unpt}.pth\n",
        "!aria2c --console-log-level=error -q -c -x 16 -s 16 -k 1M {d} -d /content/Mangio-RVC-Fork/{pretrained_base} -o f0D{target_sample_rate}{unpt}.pth\n",
        "\n",
        "print(\"Pretrain downloaded. Best of luck training!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q4a2IT5OsLTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing\n",
        "You should only need to run these cells once per model."
      ],
      "metadata": {
        "id": "GpjFLdlRFlcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Dataset\n",
        "#@markdown If it doesn't already exist, create a folder in your Google Drive named 'rvcDisconnected' and place your zip file there. This will look for the following ZIP file inside that 'rvcDisconnected' folder.\n",
        "dataset = \"dataset.zip\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown This loader will load datasets in a similar fashion to the So-Vits-SVC dataset loader. For best results, your dataset should be formatted as such:\n",
        "#@markdown ```\n",
        "#@markdown zipfile.zip\n",
        "#@markdown └───character_name\n",
        "#@markdown     ├───file1.wav\n",
        "#@markdown     ├───...\n",
        "#@markdown     └───file999.wav\n",
        "#@markdown ```\n",
        "#@markdown Audio filenames do not matter. All audio files should be in WAV format for best compatibility.\n",
        "\n",
        "# TODO: Add something to convert non-WAVs to WAV\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "directories=[]\n",
        "\n",
        "def sanitize_directory(directory):\n",
        "  for filename in os.listdir(directory):\n",
        "    file_path = os.path.join(directory, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "      if filename == \".DS_Store\" or filename.startswith(\"._\") or not filename.endswith(('.wav', '.flac', '.mp3', '.ogg', '.m4a')):\n",
        "        os.remove(file_path)\n",
        "    elif os.path.isdir(file_path):\n",
        "      #Get rid of the MACOSX directory just so it doesn't mess with renaming later\n",
        "      if(filename == \"__MACOSX\"):\n",
        "        shutil.rmtree(file_path)\n",
        "        continue\n",
        "      #Append the directory to directories for future dataset check, then recurse.\n",
        "      directories.append(file_path)\n",
        "      sanitize_directory(file_path)\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/rvcDisconnected/' + dataset\n",
        "final_directory = '/content/dataset'\n",
        "temp_directory = '/content/temp_dataset'\n",
        "\n",
        "if os.path.exists(final_directory):\n",
        "  print(\"Dataset folder already found. Wiping...\")\n",
        "  shutil.rmtree(final_directory)\n",
        "if os.path.exists(temp_directory):\n",
        "  print(\"Temporary folder already found. Wiping...\")\n",
        "  shutil.rmtree(temp_directory)\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "  raise Exception(f'I can\\'t find {dataset} in {os.path.dirname(dataset_path)}.')\n",
        "\n",
        "os.makedirs(final_directory, exist_ok=True)\n",
        "os.makedirs(temp_directory, exist_ok=True)\n",
        "#Oops.\n",
        "!unzip -d \"{temp_directory}\" -B \"{dataset_path}\"\n",
        "print(\"Sanitizing...\")\n",
        "sanitize_directory(temp_directory)\n",
        "\n",
        "if(len(directories) == 0):\n",
        "  #If there's no directories, we're dealing with a ZIP of just audio files.\n",
        "  #Move everything to /dataset/experiment_name/.\n",
        "  print(\"Dataset Type: Audio Files (Single Speaker)\")\n",
        "  expDir=os.path.join(final_directory, experiment_name)\n",
        "  os.makedirs(expDir, exist_ok=True)\n",
        "  for r, _, f in os.walk(temp_directory):\n",
        "    for name in f:\n",
        "      !cp \"{temp_directory}/{name}\" \"{expDir}\"\n",
        "elif(len(directories) == 1):\n",
        "  #If there's only one directory, we're dealing with a single speaker.\n",
        "  #Rename the folder to experiment_name and move it to /dataset/.\n",
        "  print(\"Dataset Type: Single Speaker\")\n",
        "  fi = os.path.join(temp_directory, experiment_name)\n",
        "  os.rename(directories[0], fi)\n",
        "  shutil.move(fi, final_directory)\n",
        "\n",
        "else:\n",
        "  #If anything else, we're dealing with multispeaker.\n",
        "  #Move all folders to /dataset/ indiscriminately.\n",
        "  print(\"Dataset Type: Multispeaker\")\n",
        "  for fi in directories:\n",
        "    shutil.move(fi, final_directory)\n",
        "\n",
        "shutil.rmtree(temp_directory)\n",
        "\n",
        "print(\"Dataset imported.\")\n"
      ],
      "metadata": {
        "id": "g1X5oANker6l",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocessing and Feature Extraction\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "assert cpu_threads>0, \"CPU threads not allocated correctly.\"\n",
        "\n",
        "sr = int(target_sample_rate.rstrip('k'))*1000\n",
        "pttf = path_to_training_folder + experiment_name\n",
        "os.makedirs(f\"{exp_dir}\", exist_ok=True)\n",
        "\n",
        "cmd = f\"python trainset_preprocess_pipeline_print.py \\\"{pttf}\\\" {sr} {cpu_threads} \\\"{exp_dir}\\\" 1\"\n",
        "print(cmd)\n",
        "!$cmd\n",
        "\n",
        "gpuList = gpus.split(\"-\")\n",
        "cmd = f\"python extract_f0_print.py \\\"{exp_dir}\\\" {cpu_threads} {pitch_extraction_algorithm} {crepe_hop_length}\"\n",
        "print(cmd)\n",
        "!$cmd\n",
        "\n",
        "leng = len(gpus)\n",
        "cmd = f\"python extract_feature_print.py \\\"device\\\" {leng} 0 0 \\\"{exp_dir}\\\" {model_architecture}\"\n",
        "print(cmd)\n",
        "!$cmd"
      ],
      "metadata": {
        "id": "OPNzuVYG7N_R",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save preprocessed dataset files to Google Drive\n",
        "#Compress dataset folder\n",
        "loc = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
        "!zip -r rvcLogs.zip \"{loc}\"\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "!mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "!cp /content/Mangio-RVC-Fork/rvcLogs.zip \"{DATASET_PATH_DRIVE}\""
      ],
      "metadata": {
        "id": "y959_sq7kToW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "Also includes resuming code."
      ],
      "metadata": {
        "id": "vjcmh9u_MweU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load preprocessed dataset files from Google Drive (for resuming)\n",
        "#@markdown If you already have preprocessed dataset files on Google Drive, you can load them here instead of re-running the preprocessing steps.\n",
        "import os\n",
        "\n",
        "BACK_UP_DATASET_PATH = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "\n",
        "#Prevent people from loading the ZIP over existing files\n",
        "ok=True\n",
        "if(os.path.exists(\"/content/Mangio-RVC-Fork/logs/\"+experiment_name+\"/2a_f0\")):\n",
        "  print(\"Dataset files already loaded, skipping.\")\n",
        "  ok=False\n",
        "\n",
        "if ok:\n",
        "  !unzip \"{BACK_UP_DATASET_PATH}/rvcLogs.zip\" -d /"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_BkhWhrCMdgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Model from Drive to Notebook (for resuming)\n",
        "import os\n",
        "\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name + \"/%s/\" + experiment_name\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "#@markdown Input the model's Step Count here (the number located on your model's G and D files.) If you used `save_only_last_ckpt` during training, this number will be 2333333.\n",
        "STEPCOUNT = 000 #@param {type:\"integer\"}\n",
        "\n",
        "print(\"Copying model files...\")\n",
        "!cp {DATASET_PATH_DRIVE}/D_*.pth \"{DATASET_PATH_COLAB}\"\n",
        "!cp {DATASET_PATH_DRIVE}/G_*.pth \"{DATASET_PATH_COLAB}\"\n",
        "!cp \"{DATASET_PATH_DRIVE}/config.json\" \"{DATASET_PATH_COLAB}\"\n",
        "\n",
        "print(\"Copying Tensorboard TFEVENT files...\")\n",
        "for r, _, f in os.walk(DATASET_PATH_DRIVE):\n",
        "  for name in f:\n",
        "    if(name.startswith(\"events.out.tfevents\")):\n",
        "      !cp \"{DATASET_PATH_DRIVE}/{name}\" \"{DATASET_PATH_COLAB}\"\n",
        "\n",
        "print(\"All done. Welcome back!\")"
      ],
      "metadata": {
        "id": "JbmAq_mZ7Zuh",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Index Training\n",
        "#@markdown Ensure that Feature Extraction has run successfully before running this cell.\n",
        "\n",
        "#@markdown Use this option if you wish to save the two extra files generated by index training to your Google Drive. (Only the added index is normally needed.)\n",
        "save_extra_files_to_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **Advanced:** Select this option if you would like to force the trainer to use Minibatch K-Means instead of Faiss. *Do not enable this unless you know what you're doing.*\n",
        "force_mbkm = False #@param {type:\"boolean\"}\n",
        "\n",
        "#Oh dear lord why is this baked into infer-web I hate this\n",
        "import os\n",
        "import sys\n",
        "import traceback\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "#from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "exp_dir = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
        "os.makedirs(exp_dir, exist_ok=True)\n",
        "feature_dir = (\n",
        "    \"%s/3_feature256\" % (exp_dir)\n",
        "    if model_architecture == \"v1\"\n",
        "    else \"%s/3_feature768\" % (exp_dir)\n",
        ")\n",
        "print(feature_dir)\n",
        "if not os.path.exists(feature_dir):\n",
        "  raise Exception(\"No features exist for this model yet. Did you run Feature Extraction?\")\n",
        "listdir_res = list(os.listdir(feature_dir))\n",
        "if len(listdir_res) == 0:\n",
        "  raise Exception(\"No features exist for this model yet. Did you run Feature Extraction?\")\n",
        "\n",
        "try:\n",
        "  from sklearn.cluster import MiniBatchKMeans\n",
        "except:\n",
        "  print(\"Due to a bug with Colab, we will need to reinstall Numpy real quick. Give me a sec!\")\n",
        "  !pip install -U numpy\n",
        "  print(\"Numpy reinstalled. Please restart the runtime, and then re-run the \\\"Set Training Variables\\\" cell to continue.\")\n",
        "  sys.exit()\n",
        "else:\n",
        "  print(\"Proper Numpy version detected.\")\n",
        "\n",
        "infos=[]\n",
        "npys=[]\n",
        "for name in sorted(listdir_res):\n",
        "  phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
        "  npys.append(phone)\n",
        "big_npy = np.concatenate(npys, 0)\n",
        "big_npy_idx = np.arange(big_npy.shape[0])\n",
        "np.random.shuffle(big_npy_idx)\n",
        "if big_npy.shape[0] > 2e5 or force_mbkm:\n",
        "  print(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
        "  try:\n",
        "    big_npy = (\n",
        "        MiniBatchKMeans(\n",
        "            n_clusters=\"auto\",\n",
        "            verbose=True,\n",
        "            batch_size=256,\n",
        "            compute_labels = False,\n",
        "            init=\"random\"\n",
        "        )\n",
        "        .fit(big_npy)\n",
        "        .cluster_centers_\n",
        "\n",
        "    )\n",
        "  except:\n",
        "    info = traceback.format_exc()\n",
        "    print(info)\n",
        "\n",
        "np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
        "n_ivf = min(int(16*np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "print(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
        "index = faiss.index_factory(256 if model_architecture == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
        "print(\"Training index...\")\n",
        "index_ivf = faiss.extract_index_ivf(index)\n",
        "index_ivf.nprobe = 1\n",
        "index.train(big_npy)\n",
        "faiss.write_index(\n",
        "    index,\n",
        "    \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\" % (exp_dir, n_ivf, index_ivf.nprobe, experiment_name, model_architecture)\n",
        ")\n",
        "print(\"Adding...\")\n",
        "batch_size_add = 8192\n",
        "for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "  index.add(big_npy[i:i+batch_size_add])\n",
        "faiss.write_index(\n",
        "    index,\n",
        "    \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "    % (exp_dir, n_ivf, index_ivf.nprobe, experiment_name, model_architecture)\n",
        ")\n",
        "\n",
        "npr = index_ivf.nprobe\n",
        "\n",
        "print(\"Saving files to Drive...\")\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "if(not os.path.exists(DATASET_PATH_DRIVE)):\n",
        "  !mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "if(save_extra_files_to_drive):\n",
        "  !cp \"{DATASET_PATH_COLAB}/total_fea.npy\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/trained_IVF{n_ivf}_Flat_nprobe_{npr}_{experiment_name}_{model_architecture}.index\" \"{DATASET_PATH_DRIVE}\"\n",
        "!cp \"{DATASET_PATH_COLAB}/added_IVF{n_ivf}_Flat_nprobe_{npr}_{experiment_name}_{model_architecture}.index\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"All done! Your index file has completed training.\")\n",
        "try:\n",
        "  firsttry\n",
        "except:\n",
        "  print(\"If you had to restart the runtime, disconnect and delete the runtime in order to continue. (Restarting the runtime again will not work.)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NYDdsNhx4Qdi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from random import shuffle\n",
        "\n",
        "\n",
        "assert 'model_architecture' in locals(), \"Hold up! You need to run the  \\\"Set Training Variables\\\" cell first.\"\n",
        "\n",
        "\n",
        "assert 'pretrain_type' in locals(), \"You need to download a pretrain! Please run the \\\"Download Pretrained Model\\\" cell before continuing.\"\n",
        "\n",
        "\n",
        "#@title Training\n",
        "save_frequency = 5 #@param {type:\"integer\"}\n",
        "total_epochs = 1000 #@param {type:\"integer\"}\n",
        "batch_size = 6 #@param {type:\"integer\"}\n",
        "save_only_latest_ckpt = True #@param {type:\"boolean\"}\n",
        "cache_all_training_sets = False #@param {type:\"boolean\"}\n",
        "save_small_final_model = True #@param {type:\"boolean\"}\n",
        "#@markdown **Advanced:** You can manually define a log interval here.\n",
        "use_manual_stepToEpoch = True #@param {type:\"boolean\"}\n",
        "manual_stepToEpoch = 200 #@param {type:\"integer\"}\n",
        "#@markdown **Experimental:** Enable autosave.\n",
        "enable_autosave = True #@param {type:\"boolean\"}\n",
        "\n",
        "assert save_frequency!=None, \"You need to input something for save_frequency, silly.\"\n",
        "assert save_frequency>0, \"Save frequency must be more than 0.\"\n",
        "if(save_frequency>50):print(f\"...A save frequency of {save_frequency}? A bit high, but... alright then.\")\n",
        "assert total_epochs!=None, \"You need to input something for total_epochs, silly.\"\n",
        "assert total_epochs>0, \"Total epochs must be more than 0.\"\n",
        "if(total_epochs>10000):print(f\"...A total epoch count of of {total_epochs}? This is going to overtrain, but... alright then.\")\n",
        "assert batch_size!=None, \"You need to input something for batch_size, silly.\"\n",
        "assert batch_size>0, \"Batch size must be more than 0.\"\n",
        "assert batch_size<=40, \"Batch size must be less than 40. (I'd reccomend a value between 6 and 12 for Colab.)\"\n",
        "\n",
        "pretrained_base = \"pretrained/\" if model_architecture == \"v1\" else \"pretrained_v2/\"\n",
        "unpt = f\"_{pretrain_type}\" if pretrain_type!=\"original\" else \"\"\n",
        "\n",
        "pretrainedD = f\"{pretrained_base}f0D{target_sample_rate}{unpt}.pth\"\n",
        "pretrainedG = f\"{pretrained_base}f0G{target_sample_rate}{unpt}.pth\"\n",
        "\n",
        "#Log interval\n",
        "log_interval = 1\n",
        "liFolderPath = os.path.join(exp_dir, \"1_16k_wavs\")\n",
        "if(os.path.exists(liFolderPath) and os.path.isdir(liFolderPath)):\n",
        "  wav_files = [f for f in os.listdir(liFolderPath) if f.endswith(\".wav\")]\n",
        "  if wav_files:\n",
        "    sample_size = len(wav_files)\n",
        "    log_interval = math.ceil(sample_size / batch_size)\n",
        "    if log_interval > 1:\n",
        "      log_interval += 1\n",
        "\n",
        "if log_interval > 250 and not use_manual_stepToEpoch:\n",
        "  print(f\"That's a big dataset you got there. Log interval normalized to 200 steps from {log_interval} steps.\")\n",
        "  log_interval = 200\n",
        "\n",
        "if use_manual_stepToEpoch:\n",
        "  log_interval = manual_stepToEpoch\n",
        "\n",
        "#Credit to Sonphantrung for dreaming this up.\n",
        "if enable_autosave:\n",
        "  !sed -i \"s/weights\\/\\%s/\\/content\\/drive\\/MyDrive\\/rvcDisconnected\\/$experiment_name\\/\\%s/g\" -i {now_dir}/train/process_ckpt.py\n",
        "  !sed -i \"s/.\\/logs/\\/content\\/drive\\/MyDrive\\/rvcDisconnected\\/$experiment_name\\/\\%s/g\" -i {now_dir}/train/utils.py\n",
        "\n",
        "#Create Python command\n",
        "cmd = \"python train_nsf_sim_cache_sid_load_pretrain.py -e \\\"%s\\\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s -li %s\" % (\n",
        "    experiment_name,\n",
        "    target_sample_rate,\n",
        "    1,\n",
        "    batch_size,\n",
        "    0,\n",
        "    total_epochs,\n",
        "    save_frequency,\n",
        "    \"-pg %s\" % pretrainedG if pretrainedG != \"\" else \"\\b\",\n",
        "    \"-pd %s\" % pretrainedD if pretrainedD != \"\" else \"\\b\",\n",
        "    1 if save_only_latest_ckpt else 0,\n",
        "    1 if cache_all_training_sets else 0,\n",
        "    1 if save_small_final_model else 0,\n",
        "    model_architecture,\n",
        "    log_interval,\n",
        ")\n",
        "print(cmd)\n",
        "\n",
        "#Create mute filelist\n",
        "gt_wavs_dir = f\"{exp_dir}/0_gt_wavs\"\n",
        "feature_dir = (\n",
        "  f\"{exp_dir}/3_feature256\"\n",
        "  if model_architecture == \"v1\"\n",
        "  else f\"{exp_dir}/3_feature768\"\n",
        ")\n",
        "f0_dir = f\"{exp_dir}/2a_f0\"\n",
        "f0nsf_dir = f\"{exp_dir}/2b-f0nsf\"\n",
        "names = (\n",
        "  set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        ")\n",
        "opt = []\n",
        "for name in names:\n",
        "  opt.append(\n",
        "    \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "    % (\n",
        "      gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      speaker_id,\n",
        "    )\n",
        "  )\n",
        "fea_dim = 256 if model_architecture == \"v1\" else 768\n",
        "for _ in range(2):\n",
        "  opt.append(\n",
        "      f\"{now_dir}/logs/mute/0_gt_wavs/mute{target_sample_rate}.wav|{now_dir}/logs/mute/3_feature{fea_dim}/mute.npy|{now_dir}/logs/mute/2a_f0/mute.wav.npy|{now_dir}/logs/mute/2b-f0nsf/mute.wav.npy|{speaker_id}\"\n",
        "  )\n",
        "shuffle(opt)\n",
        "with open(f\"{exp_dir}/filelist.txt\", \"w\") as f:\n",
        "  f.write(\"\\n\".join(opt))\n",
        "print(\"Mute filelist written. Best of luck training!\")\n",
        "\n",
        "\n",
        "%cd /content/Mangio-RVC-Fork\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/Mangio-RVC-Fork/logs\n",
        "\n",
        "os.chdir('/content/Mangio-RVC-Fork')\n",
        "!$cmd\n"
      ],
      "metadata": {
        "id": "Yj-_npuA_HRB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Export Model from Notebook to Drive\n",
        "import os\n",
        "\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "if(not os.path.exists(DATASET_PATH_DRIVE)):\n",
        "  !mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "#@markdown **Advanced:** Use this option if you wish to only copy over weights.\n",
        "skip_models = False #@param {type:\"boolean\"}\n",
        "#@markdown **Advanced:** Use these options if you wish to manually input your step count and epoch count for incomplete models. *Do not use this option if your training finished.*\n",
        "manual_save = False #@param {type:\"boolean\"}\n",
        "STEPCOUNT = 000 #@param {type:\"integer\"}\n",
        "EPOCHCOUNT = 000 #@param {type:\"integer\"}\n",
        "\n",
        "finished=False\n",
        "potential=\"/content/Mangio-RVC-Fork/weights/\"+experiment_name+\".pth\"\n",
        "if os.path.exists(potential):\n",
        "  finished = True\n",
        "\n",
        "#VERY hacky. Might break stuff, report to me if it does.\n",
        "print(\"Detecting latest model...\")\n",
        "if(not manual_save):\n",
        "  currentMax = 0\n",
        "  for r, _, f in os.walk(\"/content/Mangio-RVC-Fork/weights/\"):\n",
        "    for name in f:\n",
        "      if(name.endswith(\".pth\") and (name!=experiment_name+\".pth\")):\n",
        "        #Check to see if this PTH is what we're looking for.\n",
        "        if(name.find(experiment_name)==-1):\n",
        "          continue\n",
        "        #Determine Epochcount+Stepcount Phase 1\n",
        "        pot = name.split('_')\n",
        "        ep=pot[len(pot)-2][1:]\n",
        "        #If what we got from the epoch count section of the filename isn't a number, multiple completed models are in weights.\n",
        "        #Skip it if that happens.\n",
        "        if(not ep.isdecimal()):\n",
        "          continue\n",
        "        #Determine Epochcount+Stepcount Phase 2\n",
        "        ep=int(ep)\n",
        "        if ep>currentMax:\n",
        "          currentMax=ep\n",
        "          step=pot[len(pot)-1].split('.')\n",
        "          step=int(step[0][1:])\n",
        "          EPOCHCOUNT=ep\n",
        "          STEPCOUNT=step\n",
        "\n",
        "TSTEP = STEPCOUNT\n",
        "if(not skip_models):\n",
        "  print(\"Copying model files...\")\n",
        "  if(save_only_latest_ckpt):\n",
        "    TSTEP=2333333\n",
        "  !cp \"{DATASET_PATH_COLAB}/D_{TSTEP}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/G_{TSTEP}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/config.json\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"Copying Tensorboard TFEVENT files...\")\n",
        "for r, d, f in os.walk(DATASET_PATH_COLAB):\n",
        "  for name in f:\n",
        "    if(name.startswith(\"events.out.tfevents\") and os.path.exists(os.path.join(DATASET_PATH_COLAB, name))):\n",
        "      !cp \"{DATASET_PATH_COLAB}/{name}\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"Copying weight file...\")\n",
        "if(finished):\n",
        "  !cp \"{potential}\" \"{DATASET_PATH_DRIVE}\"\n",
        "else:\n",
        "  !cp \"/content/Mangio-RVC-Fork/weights/{experiment_name}_e{EPOCHCOUNT}_s{STEPCOUNT}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"All done!\")"
      ],
      "metadata": {
        "id": "HDsTxpbTqHol",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changelogs, Credits, and Special Thanks\n",
        "\n",
        "**Changelogs**\n",
        "\n",
        "**v0.28** - Added Blaise-TK's TITAN pretrains. Added an experimental autosave feature as implemented by [Sonphantrung's Disconnected fork](https://colab.research.google.com/drive/1o4NbL2pCOkc6s5u_vyIReujwCetraTKb); let me know if things break.\n",
        "\n",
        "Older changelogs can be found at https://rentry.co/rvcdisconnected_changelogs.\n",
        "\n",
        "**Credits**\n",
        "*   [Kit Lemonfoot](https://huggingface.co/Kit-Lemonfoot) - writing this notebook\n",
        "*   [RVC Project](https://github.com/RVC-Project) - Created RVC, obviously\n",
        "*   [Mangio261](https://github.com/Mangio621/) - Creating the Mangio RVC fork\n",
        "*   [Kalomaze](https://github.com/kalomaze) - Original RVC colab + Mangio tweaks\n",
        "*   [Alexlnkp](https://github.com/alexlnkp) - Created a more up-to-date variant of the Mangio-RVC fork\n",
        "*   [LollenApe](https://huggingface.co/lollenape) - Created the \"Export Finished Model to HuggingFace\" cell\n",
        "*   [Sonphantrung](https://github.com/sonphantrung) - Autosave solution, large amounts of code auditing and adjustments\n",
        "*   [LJ1995](https://huggingface.co/lj1995) - Pretrained RVC models\n",
        "*   [SimplCup](https://huggingface.co/SimplCup) - OV2Super pretrained RVC models\n",
        "*   [MUSTAR](https://huggingface.co/MUSTAR) - RIN_E3 and SnowieRU pretrained RVC models\n",
        "*   [TheStinger / Ilaria](https://huggingface.co/TheStinger) - ItaIla pretrained RVC models\n",
        "*   [Blaise-TK](https://huggingface.co/blaise-tk) - TITAN pretrained RVC models\n",
        "*   [Pony Preservation Project](https://boards.4channel.org/mlp/catalog#s=Pony%20Preservation%20Project) - for their robust TalkNet and So-Vits-SVC notebooks\n",
        "*   the Colab team - forcing my hand and making me release this notebook early\n",
        "\n",
        "**Special Thanks**\n",
        "*   [Fifteen AI](https://15.ai/) - for getting me into voice AI in the first place\n",
        "*   [Dacoolkid44](https://huggingface.co/dacoolkid44) / [HoloAI44](https://www.youtube.com/@Holo_AI44) and Hijack / [SANSSWEEP](https://huggingface.co/SANSSWEEP) - for basically kickstarting the larger VTuber voice AI scene with their models\n",
        "*   [Maki Ligon](https://www.youtube.com/@Shiina_Mashiro) / [Yuuto Ichika](https://www.youtube.com/@yuutoichika) - for keeping me grounded in reality while developing this thing\n",
        "*   [Bartezes](https://www.youtube.com/@bartezes3082) - for helping me so much with the [VTuber AI Model Tracking spreadsheet](https://docs.google.com/spreadsheets/d/1tvZSggOsZGAPjbMrWOAAaoJJFpJuQlwUEQCf5x1ssO8/)\n",
        "*   [Megaaziib](https://www.youtube.com/@megaaziib) - for inspiring me to keep working on AI models and covers (I don't hate you)\n",
        "*   [Saintlysaint](https://www.youtube.com/@SaintlySaint) and [Gengar2525](https://www.youtube.com/@GeGaCh) - for having faith in me\n"
      ],
      "metadata": {
        "id": "g3fR68Yfkayg"
      }
    }
  ]
}